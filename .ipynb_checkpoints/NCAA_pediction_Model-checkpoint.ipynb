{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa307109",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "Drop column with extera catigorical data or data that just give bias to prefered players: usage, college year, ht, num, pfr, year, rec rank, pick, pik drafted, gbpm, offensive gdbm, defensive gdbm, type, Recruit Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2171391a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61061, 60)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('trainingData/CollegeBasketballPlayers2009-2021.csv', low_memory=False)\n",
    "df = df.rename(columns = {'Unnamed: 64' : 'role_position'})\n",
    "df = df.drop('Unnamed: 65', axis=1) # Has no meaning in the dataset\n",
    "df = df.drop('player_name', axis=1) # player name should not determine player's performance score\n",
    "df = df.drop('ht', axis=1) # Temporarily excluding this column due to inconsistent date formats and other values\n",
    "df = df.drop('num', axis=1) # It might denote a player's choice or position but with significant variation in meaning.\n",
    "df = df.drop('type', axis=1) # Column has 1 unique value\n",
    "df= df.drop('pid', axis=1) # catigorical, not needed \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1796e1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Rec Rank': Number of NaN: 42591 Percentage: 69.75%\n",
      "Column 'pick': Number of NaN: 59626 Percentage: 97.65%\n"
     ]
    }
   ],
   "source": [
    "# Count and remove columns with over 60% nan values \n",
    "total = len(df)\n",
    "for column in df.columns:\n",
    "    count = df[column].isna().sum()\n",
    "    percent= (count/ total) * 100\n",
    "    if (percent>=60):\n",
    "        print(f\"Column '{column}':\", f\"Number of NaN: {count}\", f\"Percentage: {percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71cebfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('pick', axis=1) \n",
    "df = df.drop('Rec Rank', axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440ee9cf",
   "metadata": {},
   "source": [
    "fill in missing values using knn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "139e7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_label_encoder = LabelEncoder()\n",
    "df['team'] = team_label_encoder.fit_transform(df['team'])\n",
    "\n",
    "conf_label_encoder = LabelEncoder()\n",
    "df['conf'] = conf_label_encoder.fit_transform(df['conf'])\n",
    "\n",
    "yr_label_encoder = LabelEncoder()\n",
    "df['yr'] = yr_label_encoder.fit_transform(df['yr'])\n",
    "\n",
    "role_position_label_encoder = LabelEncoder()\n",
    "df['role_position'] = role_position_label_encoder.fit_transform(df['role_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb0bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=10)\n",
    "imputed_numeric = imputer.fit_transform(df.select_dtypes(include=np.number))\n",
    "dfBasketballTraining_filled = pd.DataFrame(imputed_numeric, columns=df.select_dtypes(include=np.number).columns)\n",
    "string_columns = df.select_dtypes(include='object').columns\n",
    "imputed_data = pd.concat([df[string_columns], dfBasketballTraining_filled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456b23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the imputed data back to a pandas DataFrame\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc879073",
   "metadata": {},
   "source": [
    "Remove redundancy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbca026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = imputed_df.corr()\n",
    "\n",
    "# # Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad0d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find any corrilation >=.9 to determine redundant features \n",
    "threshold = 0.9  \n",
    "\n",
    "# Iterate through the correlation matrix and print highly correlated pairs\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i + 1, len(correlation_matrix.columns)):  # Added a closing parenthesis here\n",
    "        if abs(correlation_matrix.iloc[i, j]) >= threshold:\n",
    "            print(f\"{correlation_matrix.columns[i]} and {correlation_matrix.columns[j]}: {correlation_matrix.iloc[i, j]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove redundancy\n",
    "imputed_df= imputed_df.drop('rimmade', axis=1) \n",
    "imputed_df= imputed_df.drop('rimmade+rimmiss', axis=1) \n",
    "imputed_df= imputed_df.drop('Ortg', axis=1) \n",
    "imputed_df= imputed_df.drop('Min_per', axis=1) \n",
    "imputed_df= imputed_df.drop('eFG', axis=1) \n",
    "imputed_df= imputed_df.drop('drtg', axis=1)\n",
    "imputed_df= imputed_df.drop('stops', axis=1)\n",
    "imputed_df= imputed_df.drop('gbpm', axis=1)\n",
    "imputed_df= imputed_df.drop('dreb', axis=1)\n",
    "imputed_df= imputed_df.drop('yr', axis=1)\n",
    "imputed_df= imputed_df.drop('midmade+midmiss', axis=1)\n",
    "imputed_df= imputed_df.drop('dunksmiss+dunksmade', axis=1)\n",
    "imputed_df= imputed_df.drop('twoPA', axis=1)\n",
    "imputed_df= imputed_df.drop('TPA', axis=1)\n",
    "imputed_df= imputed_df.drop('FTA', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b6863",
   "metadata": {},
   "source": [
    "## Transform "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4564ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc2023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f53d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
